{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f20120a",
   "metadata": {},
   "source": [
    "# NumPy exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c7e7157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# ^^^ pyforest auto-imports - don't write above this line\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "694dafbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5]\n",
      "shape of a1: (5,)\n",
      "[[2 6 4]\n",
      " [5 8 3]]\n",
      "shape of a2: (2, 3)\n",
      "[[1 2]\n",
      " [3 4]\n",
      " [4 3]]\n",
      "shape of a3: (3, 2)\n"
     ]
    }
   ],
   "source": [
    "a1 = np.array([1, 2,  3, 4, 5])\n",
    "print(a1)\n",
    "print(\"shape of a1: \" + str(a1.shape))\n",
    "\n",
    "a2 = np.array([\n",
    "    [2, 6, 4], \n",
    "    [5, 8, 3]\n",
    "])\n",
    "print(a2)\n",
    "print(\"shape of a2: \" + str(a2.shape))\n",
    "\n",
    "a3 = np.array([\n",
    "    [1, 2], [3, 4],\n",
    "    [4, 3]\n",
    "])\n",
    "print(a3)\n",
    "print(\"shape of a3: \" + str(a3.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fadfa4c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9b67516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 6, 4],\n",
       "       [5, 8, 3]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc792281",
   "metadata": {},
   "outputs": [],
   "source": [
    "d3_array = np.array([\n",
    "    [1, 2], [3, 4],\n",
    "    [4, 3], [1, 7]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c977b99b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4],\n",
       "       [4, 3],\n",
       "       [1, 7]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d3_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c28ea64c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1_array.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7e9d350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport numpy as np'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport numpy as np'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key: 0 | of type: <class 'int'>\n",
      "\n",
      "value: \n",
      "0    1.0\n",
      "1    4.0\n",
      "2    4.2\n",
      "Name: 0, dtype: float64 | of type: <class 'pandas.core.series.Series'>\n",
      "-----------\n",
      "key: 1 | of type: <class 'int'>\n",
      "\n",
      "value: \n",
      "0    2.0\n",
      "1    5.0\n",
      "2    5.6\n",
      "Name: 1, dtype: float64 | of type: <class 'pandas.core.series.Series'>\n",
      "-----------\n",
      "key: 2 | of type: <class 'int'>\n",
      "\n",
      "value: \n",
      "0    3.0\n",
      "1    6.0\n",
      "2    9.9\n",
      "Name: 2, dtype: float64 | of type: <class 'pandas.core.series.Series'>\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "for key, value in pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [4.2, 5.6, 9.9]])).items():\n",
    "    print(\"key: \" + str(key), \"| of type: \" + str(type(key)))\n",
    "    print()\n",
    "    print(\"value: \")\n",
    "    print(str(value), \"| of type: \" + str(type(value)))\n",
    "    print(\"-----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25e50ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport numpy as np'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport numpy as np'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df1 = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [4.2, 5.6, 9.9]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f740239f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport numpy as np'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[1. , 2. , 3. ],\n",
       "       [4. , 5. , 6. ],\n",
       "       [4.2, 5.6, 9.9]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[1, 2, 3], [4, 5, 6], [4.2, 5.6, 9.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fcd4ceac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"Example Column\"] = [8, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf8a7e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>Example Column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.2</td>\n",
       "      <td>5.6</td>\n",
       "      <td>9.9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2  Example Column\n",
       "0  1.0  2.0  3.0               8\n",
       "1  4.0  5.0  6.0               3\n",
       "2  4.2  5.6  9.9               4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e65ece67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key: 0 | of type: <class 'int'>\n",
      "\n",
      "value: \n",
      "0    1.0\n",
      "1    4.0\n",
      "2    4.2\n",
      "Name: 0, dtype: float64 | of type: <class 'pandas.core.series.Series'>\n",
      "-----------\n",
      "key: 1 | of type: <class 'int'>\n",
      "\n",
      "value: \n",
      "0    2.0\n",
      "1    5.0\n",
      "2    5.6\n",
      "Name: 1, dtype: float64 | of type: <class 'pandas.core.series.Series'>\n",
      "-----------\n",
      "key: 2 | of type: <class 'int'>\n",
      "\n",
      "value: \n",
      "0    3.0\n",
      "1    6.0\n",
      "2    9.9\n",
      "Name: 2, dtype: float64 | of type: <class 'pandas.core.series.Series'>\n",
      "-----------\n",
      "key: Example Column | of type: <class 'str'>\n",
      "\n",
      "value: \n",
      "0    8\n",
      "1    3\n",
      "2    4\n",
      "Name: Example Column, dtype: int64 | of type: <class 'pandas.core.series.Series'>\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "for key, value in df1.items():\n",
    "    print(\"key: \" + str(key), \"| of type: \" + str(type(key)))\n",
    "    print()\n",
    "    print(\"value: \")\n",
    "    print(str(value), \"| of type: \" + str(type(value)))\n",
    "    print(\"-----------\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f64d61ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1c0ed649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport numpy as np'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport numpy as np'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7\n",
       "0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       "1  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       "2  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       "3  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       "4  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame(np.ones(shape=(5, 8)))\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "52823159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [1.0, 1.0, 1.0, 1.0, 1.0],\n",
       " 1: [1.0, 1.0, 1.0, 1.0, 1.0],\n",
       " 2: [1.0, 1.0, 1.0, 1.0, 1.0],\n",
       " 3: [1.0, 1.0, 1.0, 1.0, 1.0],\n",
       " 4: [1.0, 1.0, 1.0, 1.0, 1.0]}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 1\n",
    "shuffle = False\n",
    "batch_dict = {}\n",
    "if shuffle:\n",
    "    index_iterator = iter(np.random.permutation(len(df1)))  \n",
    "else:\n",
    "    index_iterator = range(len(df1))\n",
    "\n",
    "    # Initialize batch, construct batch, append to batch_dict\n",
    "batch = []\n",
    "for index in index_iterator:  # iterate over indices using the iterator\n",
    "    batch.append(df1[index])\n",
    "# Initialize batch_dict, will be yielded\n",
    "batch_dict = {}\n",
    "for data_dict in batch:\n",
    "    for key, value in data_dict.items():\n",
    "        if key not in batch_dict:\n",
    "            batch_dict[key] = [] # initializes column with key, if column doesn't exist\n",
    "        batch_dict[key].append(value) # adds values to said column\n",
    "if len(batch) == batch_size:\n",
    "    batch_dict.append(batch)  # use yield keyword to define an iterable generator\n",
    "    batch = []\n",
    "batch_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dcac696c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1.0\n",
      "1    1.0\n",
      "2    1.0\n",
      "3    1.0\n",
      "4    1.0\n",
      "Name: 0, dtype: float64\n",
      "0    1.0\n",
      "1    1.0\n",
      "2    1.0\n",
      "3    1.0\n",
      "4    1.0\n",
      "Name: 1, dtype: float64\n",
      "0    1.0\n",
      "1    1.0\n",
      "2    1.0\n",
      "3    1.0\n",
      "4    1.0\n",
      "Name: 2, dtype: float64\n",
      "0    1.0\n",
      "1    1.0\n",
      "2    1.0\n",
      "3    1.0\n",
      "4    1.0\n",
      "Name: 3, dtype: float64\n",
      "0    1.0\n",
      "1    1.0\n",
      "2    1.0\n",
      "3    1.0\n",
      "4    1.0\n",
      "Name: 4, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for index in index_iterator:  # iterate over indices using the iterator\n",
    "    print(df1[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9edbf3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    \"\"\"\n",
    "    Dataloader Class\n",
    "    Defines an iterable batch-sampler over a given dataset\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, batch_size=1, shuffle=False, drop_last=False, verbose=False):\n",
    "        \"\"\"\n",
    "        :param dataset: dataset from which to load the data\n",
    "        :param batch_size: how many samples per batch to load\n",
    "        :param shuffle: set to True to have the data reshuffled at every epoch\n",
    "        :param drop_last: set to True to drop the last incomplete batch,\n",
    "            if the dataset size is not divisible by the batch size.\n",
    "            If False and the size of dataset is not divisible by the batch\n",
    "            size, then the last batch will be smaller.\n",
    "        \"\"\"\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.drop_last = drop_last\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def __iter__(self):\n",
    "        ########################################################################\n",
    "        # TODO:                                                                #\n",
    "        # Define an iterable function that samples batches from the dataset.   #\n",
    "        # Each batch should be a dict containing numpy arrays of length        #\n",
    "        # batch_size (except for the last batch if drop_last=True)             #\n",
    "        # Hints:                                                               #\n",
    "        #   - np.random.permutation(n) can be used to get a list of all        #\n",
    "        #     numbers from 0 to n-1 in a random order                          #\n",
    "        #   - To load data efficiently, you should try to load only those      #\n",
    "        #     samples from the dataset that are needed for the current batch.  #\n",
    "        #     An easy way to do this is to build a generator with the yield    #\n",
    "        #     keyword, see https://wiki.python.org/moin/Generators             #\n",
    "        #   - Have a look at the \"DataLoader\" notebook first. This function is #\n",
    "        #     supposed to combine the functions:                               #\n",
    "        #       - combine_batch_dicts                                          #\n",
    "        #       - batch_to_numpy                                               #\n",
    "        #       - build_batch_iterator                                         #\n",
    "        #     in section 1 of the notebook.                                    #\n",
    "        ########################################################################\n",
    "        # depending on shuffle condition, iterate over indeces in dataset\n",
    "        if self.shuffle:\n",
    "            index_iterator = iter(np.random.permutation(len(self.dataset)))  \n",
    "        else:\n",
    "            index_iterator = iter(range(len(self.dataset)))\n",
    "        # Initialize batch_dict, will be yielded\n",
    "        batch_dict = {}\n",
    "        \n",
    "        # Initialize batch, construct batch, append to batch_dict\n",
    "        batch = []\n",
    "        for index in index_iterator:  # iterate over indices using the iterator\n",
    "            batch.append(self.dataset[index])\n",
    "            if self.verbose:\n",
    "                print(index)\n",
    "            for data_dict in batch:\n",
    "                for key, value in data_dict.items():\n",
    "                    if key not in batch_dict:\n",
    "                        batch_dict[key] = [] # initializes column with key, if column doesn't exist\n",
    "                    batch_dict[key].append(value) # adds values to said column\n",
    "\n",
    "            # turn batch_dict into dict of numpy arrays\n",
    "            numpy_batch = {}        \n",
    "            for key, value in batch_dict.items():\n",
    "                numpy_batch[key] = np.array(value)\n",
    "                \n",
    "            if len(batch) == self.batch_size:                    \n",
    "                yield numpy_batch  # use yield keyword to define an iterable generator\n",
    "            batch = []\n",
    "            if len(batch) > 0 and not self.drop_last:\n",
    "                yield numpy_batch\n",
    "              \n",
    "\n",
    "        ########################################################################\n",
    "        #                           END OF YOUR CODE                           #\n",
    "        ########################################################################\n",
    "\n",
    "    def __len__(self):\n",
    "        length = None\n",
    "        ########################################################################\n",
    "        # TODO:                                                                #\n",
    "        # Return the length of the dataloader                                  #\n",
    "        # Hint: this is the number of batches you can sample from the dataset. #\n",
    "        # Don't forget to check for drop last!                                 #\n",
    "        ########################################################################\n",
    "\n",
    "        \n",
    "        if self.drop_last:\n",
    "            length = len(self.dataset) // self.batch_size # floor division\n",
    "        else:\n",
    "            if len(self.dataset) % self.batch_size > 0:\n",
    "                length = int(len(self.dataset)/self.batch_size + 1)\n",
    "            else:\n",
    "                length = len(self.dataset)/self.batch_size\n",
    "            \n",
    "\n",
    "        ########################################################################\n",
    "        #                           END OF YOUR CODE                           #\n",
    "        ########################################################################\n",
    "        return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1dfec7a0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport numpy as np'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport numpy as np'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport numpy as np'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport numpy as np'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport numpy as np'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{0: [array([[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]])],\n",
       " 1: [array([[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]])],\n",
       " 2: [array([[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]])],\n",
       " 3: [array([[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]])],\n",
       " 4: [array([[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]])]}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pixel():\n",
    "    return np.ndarray(shape=(3,))\n",
    "\n",
    "def picture(heigth=2, width=3):\n",
    "    pass\n",
    "\n",
    "import random\n",
    "raw_data = {}\n",
    "for key in range(5):\n",
    "    if key not in raw_data.keys():\n",
    "        raw_data[key] = []\n",
    "    raw_data[key].append(np.ndarray(shape=(5, 3)))\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "95ab9f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport numpy as np'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_data = np.ndarray(shape=(5, 3, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0958c1eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(raw_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "77b936e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport numpy as np'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([4.24399158e-314, 8.48798317e-314, 1.27319747e-313])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "36716fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [raw_data, raw_data, raw_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e1a69222",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(data, batch_size=2, shuffle=False, drop_last=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "56d595be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.DataLoader at 0x1d98e51beb0>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f9255dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [106], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dl:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(batch)\n",
      "Cell \u001b[1;32mIn [87], line 57\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28mprint\u001b[39m(index)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data_dict \u001b[38;5;129;01min\u001b[39;00m batch:\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdata_dict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m():\n\u001b[0;32m     58\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m batch_dict:\n\u001b[0;32m     59\u001b[0m             batch_dict[key] \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;66;03m# initializes column with key, if column doesn't exist\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "for batch in dl:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aff3696",
   "metadata": {},
   "source": [
    "for index in index_iterator:  # iterate over indices using the iterator\n",
    "            batch.append(self.dataset[index])\n",
    "\n",
    "            for data_dict in batch:\n",
    "                for key, value in data_dict.items():\n",
    "                    if key not in batch_dict:\n",
    "                        batch_dict[key] = [] # initializes column with key, if column doesn't exist\n",
    "                    batch_dict[key].append(value) # adds values to said column\n",
    "\n",
    "            # turn batch_dict into dict of numpy arrays\n",
    "            numpy_batch = {}        \n",
    "            for key, value in batch_dict.items():\n",
    "                numpy_batch[key] = np.array(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d63648",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
